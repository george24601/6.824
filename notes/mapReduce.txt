Preview question
How soon after it receives the first file of intermediate data can a reduce worker start calling the application's Reduce function? Explain your answer.


-------
 Three big kinds of abstraction:
    Storage.
    Communication.
    Computation.

 Consistency and performance are enemies.

Example: word count
  input is thousands of text files
  Map(k, v)
    split v into words
    for each word w
      emit(w, "1")
  Reduce(k, v)
    emit(len(v))

  Hard to build a network than can run 1000x faster than a single computer.
  So they cared about minimizing movement of data over the network.

  MR re-runs just the failed Map()s and Reduce()s.
    They are pure functions -- they don't modify their inputs,
      they don't keep state, there's no shared memory, there's
      no map/map or reduce/reduce interaction.
    So re-execution is likely to yield the same output.

  The requirement for pure functions is a major limitation of
    MR compared to other parallel programming schemes.
    But it's critical to MR's simplicity.


  master: gives tasks to workers; remembers where intermediate output is
  M input splits
  input stored in GFS, 3 copies of each split
  all computers run both GFS and MR workers
  many more input splits than workers
  master starts a Map task on each server
    hands out new tasks as old ones finish
  worker hashes Map output by key into R partitions, on local disk
  no Reduce calls until all Maps are finished
  master tells Reducers to fetch intermediate data partitions from Map workers
  Reduce workers write final output to GFS

  Map input is read from local disks, not over network.
  Intermediate data goes over network just once.
    Stored on local disk, not GFS.
  Intermediate data partitioned into files holding many keys.
    Big network transfers are more efficient.

Solution: many more splits than workers.

some Reduce workers may already have read failed worker's intermediate data.
      here we depend on functional and deterministic Map()!

how does the master know the worker crashed? (pings)
    master need not re-run Map if Reduces have fetched all intermediate data
      though then a Reduce crash would have to wait for Maps to re-run
  * Reduce worker crashes before producing output.
    master re-starts its tasks on another worker.
  * Reduce worker crashes in the middle of writing its output.
    GFS has atomic rename that prevents output from being visible until complete.
    so it's safe for the master to re-run the Reduce tasks somewhere else.


Other failures/problems:
  * What if the master accidentally starts *two* Map() workers on same input?
    it will tell Reduce workers about only one of them.
  * What if two Reduce() workers for the same partition of intermediate data?
    they will both try to write the same output file on GFS!
    atomic GFS rename will cause the second to finish to win.
  * What if a single worker is very slow -- a "straggler"?
    perhaps due to flakey hardware.
    master starts a second copy of last few tasks.
  * What if a worker computes incorrect output, due to broken h/w or s/w?
    too bad! MR assumes "fail-stop" CPUs and software.
  * What if the master crashes?

  Not everything fits the map/shuffle/reduce pattern.
  Small data, since overheads are high. E.g. not web site back-end.
  Small updates to big data, e.g. add a few documents to a big index
  Unpredictable reads (neither Map nor Reduce can choose input)
  Multiple shuffles, e.g. page-rank (can use multiple MR but not very efficient)
  More flexible systems allow these, but more complex model.

------
